{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a63d9a8-31c8-486a-b32a-d13687f204a2",
   "metadata": {},
   "source": [
    "## Train baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec993818-46ec-4008-b32c-dd372570033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from product_classification.data_processing.text_processing import EStemTag, Lemmatizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "30b7d5a6-423d-4fd1-81c1-c596baf181ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data\"\n",
    "with open(f\"{path}/datasets.pkl\", \"rb\") as handle:\n",
    "    simple_datasets = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e411c4e-c648-4a70-88e5-963082dcb0c4",
   "metadata": {},
   "source": [
    "### Categorical features transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "922bd36e-84c8-4be1-94e1-ecf82a9ecd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"merchant_name\", \"brand_name\"]\n",
    "categorical_transformer = OneHotEncoder(drop=\"first\" ,handle_unknown=\"ignore\", dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac0a292-9e4b-4920-876b-9a85b9d83d2e",
   "metadata": {},
   "source": [
    "### Numerical features transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c86c079-5cf1-43d5-bd48-1182c18eb9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"price\"]\n",
    "numeric_transformer = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65449bac-0cbf-4d85-8c34-3d428cf64b8e",
   "metadata": {},
   "source": [
    "### Text transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2e9825b-5218-46a7-b5cd-6530b3c39543",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = \"product_name\"\n",
    "\n",
    "stem_tag = EStemTag.STEMMER\n",
    "lemma = Lemmatizer(stem=stem_tag)\n",
    "\n",
    "text_transformer = Pipeline(\n",
    "    [(stem_tag.value, lemma),\n",
    "    (\"tfidf\" ,TfidfVectorizer())]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a284e8-4978-496d-9f57-ff196330dd60",
   "metadata": {},
   "source": [
    "### Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e6fd31a-73b9-4238-bebe-7760c5b5f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "            (\"text\", text_transformer, text_features)\n",
    "                     ]\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83755606-a826-48ff-85a4-a87673212dad",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b1c0380-cedd-4cd2-99d2-8c5a4397965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LGBMClassifier(objective=\"binary\", random_state=42, silent=False, metric=\"binary_logloss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "345b2de8-9bcf-4808-ab1e-e206dad8a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_classifier = MultiOutputClassifier(classifier, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08100abf-f576-4959-b483-41cb602c5008",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44a2eada-7cf2-4190-85f9-c52bfd4368cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", multilabel_classifier)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d88eac-0c14-42cb-bef1-997a9fca6a91",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c7156ce-0426-4203-b7c4-b0d07dee6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = simple_datasets.training.iloc[:,1:5], simple_datasets.training.iloc[:,5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f39b0502-dbf7-4340-9d8f-e93b24500efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Number of positive: 781, number of negative: 129638\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 25.759037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.005988 -> initscore=-5.111926\n",
      "[LightGBM] [Info] Start training from score -5.111926\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Number of positive: 8511, number of negative: 121908\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 26.217774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065259 -> initscore=-2.661907\n",
      "[LightGBM] [Info] Start training from score -2.661907\n",
      "[LightGBM] [Info] Number of positive: 8503, number of negative: 121916\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 25.663411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;price&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                dtype=&lt;class &#x27;int&#x27;&gt;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;merchant_name&#x27;,\n",
       "                                                   &#x27;brand_name&#x27;]),\n",
       "                                                 (&#x27;text&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;stemmer&#x27;,\n",
       "                                                                   Lemmatizer(stem=&lt;EStemTag.STEMMER: &#x27;stemmer&#x27;&gt;)),\n",
       "                                                                  (&#x27;tfidf&#x27;,\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  &#x27;product_name&#x27;)])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 MultiOutputClassifier(estimator=LGBMClassifier(metric=&#x27;binary_logloss&#x27;,\n",
       "                                                                objective=&#x27;binary&#x27;,\n",
       "                                                                random_state=42,\n",
       "                                                                silent=False),\n",
       "                                       n_jobs=-1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;price&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                dtype=&lt;class &#x27;int&#x27;&gt;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;merchant_name&#x27;,\n",
       "                                                   &#x27;brand_name&#x27;]),\n",
       "                                                 (&#x27;text&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;stemmer&#x27;,\n",
       "                                                                   Lemmatizer(stem=&lt;EStemTag.STEMMER: &#x27;stemmer&#x27;&gt;)),\n",
       "                                                                  (&#x27;tfidf&#x27;,\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  &#x27;product_name&#x27;)])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 MultiOutputClassifier(estimator=LGBMClassifier(metric=&#x27;binary_logloss&#x27;,\n",
       "                                                                objective=&#x27;binary&#x27;,\n",
       "                                                                random_state=42,\n",
       "                                                                silent=False),\n",
       "                                       n_jobs=-1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(), [&#x27;price&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                               dtype=&lt;class &#x27;int&#x27;&gt;,\n",
       "                                               handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;merchant_name&#x27;, &#x27;brand_name&#x27;]),\n",
       "                                (&#x27;text&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;stemmer&#x27;,\n",
       "                                                  Lemmatizer(stem=&lt;EStemTag.STEMMER: &#x27;stemmer&#x27;&gt;)),\n",
       "                                                 (&#x27;tfidf&#x27;, TfidfVectorizer())]),\n",
       "                                 &#x27;product_name&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;price&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;merchant_name&#x27;, &#x27;brand_name&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, dtype=&lt;class &#x27;int&#x27;&gt;, handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>product_name</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lemmatizer</label><div class=\"sk-toggleable__content\"><pre>Lemmatizer(stem=&lt;EStemTag.STEMMER: &#x27;stemmer&#x27;&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LGBMClassifier(metric=&#x27;binary_logloss&#x27;,\n",
       "                                               objective=&#x27;binary&#x27;,\n",
       "                                               random_state=42, silent=False),\n",
       "                      n_jobs=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(metric=&#x27;binary_logloss&#x27;, objective=&#x27;binary&#x27;, random_state=42,\n",
       "               silent=False)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(metric=&#x27;binary_logloss&#x27;, objective=&#x27;binary&#x27;, random_state=42,\n",
       "               silent=False)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  ['price']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(drop='first',\n",
       "                                                                dtype=<class 'int'>,\n",
       "                                                                handle_unknown='ignore'),\n",
       "                                                  ['merchant_name',\n",
       "                                                   'brand_name']),\n",
       "                                                 ('text',\n",
       "                                                  Pipeline(steps=[('stemmer',\n",
       "                                                                   Lemmatizer(stem=<EStemTag.STEMMER: 'stemmer'>)),\n",
       "                                                                  ('tfidf',\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  'product_name')])),\n",
       "                ('classifier',\n",
       "                 MultiOutputClassifier(estimator=LGBMClassifier(metric='binary_logloss',\n",
       "                                                                objective='binary',\n",
       "                                                                random_state=42,\n",
       "                                                                silent=False),\n",
       "                                       n_jobs=-1))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train, classifier__verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2582a0-1590-41f2-8601-b8a333f6e0bf",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff40f8c7-b574-40aa-b750-a365ecc37b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = simple_datasets.test.iloc[:,1:5], simple_datasets.test.iloc[:,5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e79a293-bdcf-41d2-a3a7-6f76d3db62b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:188: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71e1fb7c-d42c-421d-9ed9-e4e20297ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd86e8a9-89f7-4544-98d7-dde2d573a08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                        animalerie       0.95      0.84      0.89       691\n",
      "                      auto et moto       0.84      0.59      0.70       350\n",
      "                   bagages et sacs       0.86      0.70      0.77       290\n",
      "                  beaute et parfum       0.94      0.90      0.92       757\n",
      "              bebe et puericulture       0.92      0.64      0.75       399\n",
      "                            bijoux       0.96      0.88      0.92       361\n",
      "                         bricolage       0.85      0.61      0.71       753\n",
      "                     cd et vinyles       0.58      0.37      0.45        30\n",
      "         chaussures et accessoires       0.94      0.87      0.90       703\n",
      "    commerce, industrie et science       0.28      0.24      0.26        29\n",
      "                 cuisine et maison       0.87      0.57      0.69       758\n",
      "                    dvd et blu-ray       0.98      0.93      0.96       103\n",
      "                          epicerie       0.92      0.93      0.92       752\n",
      "forfaits et accessoires operateurs       0.37      0.59      0.45        34\n",
      "             fournitures de bureau       0.91      0.67      0.78       523\n",
      "               gros electromenager       0.80      0.67      0.73        60\n",
      "                         high-tech       0.92      0.78      0.85       750\n",
      "                  hygiene et sante       0.91      0.59      0.72       762\n",
      "    instruments de musique et sono       0.70      0.53      0.61        81\n",
      "                            jardin       0.89      0.54      0.67       428\n",
      "                    jeux et jouets       0.91      0.54      0.68       757\n",
      "                        jeux video       0.88      0.75      0.81       319\n",
      "                            livres       0.73      0.71      0.72       369\n",
      "                 livres numeriques       0.42      0.16      0.23        31\n",
      "                         logiciels       0.02      0.07      0.03        14\n",
      "           luminaires et eclairage       0.91      0.82      0.86       211\n",
      "                           montres       0.74      0.86      0.79        69\n",
      "                 sports et loisirs       0.87      0.53      0.66       484\n",
      "                         vetements       0.96      0.95      0.96       750\n",
      "\n",
      "                         micro avg       0.89      0.72      0.80     11618\n",
      "                         macro avg       0.79      0.65      0.70     11618\n",
      "                      weighted avg       0.89      0.72      0.79     11618\n",
      "                       samples avg       0.71      0.73      0.72     11618\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/okteto/product_classification/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Number of positive: 8515, number of negative: 121904\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 24.449557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065290 -> initscore=-2.661405\n",
      "[LightGBM] [Info] Start training from score -2.661405\n",
      "[LightGBM] [Info] Number of positive: 8512, number of negative: 121907\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 24.814204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065267 -> initscore=-2.661782\n",
      "[LightGBM] [Info] Start training from score -2.661782\n",
      "[LightGBM] [Info] Number of positive: 3581, number of negative: 126838\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 22.495586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.027458 -> initscore=-3.567269\n",
      "[LightGBM] [Info] Start training from score -3.567269\n",
      "[LightGBM] [Info] Number of positive: 2387, number of negative: 128032\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 22.222276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018303 -> initscore=-3.982243\n",
      "[LightGBM] [Info] Start training from score -3.982243\n",
      "[LightGBM] [Info] Number of positive: 3285, number of negative: 127134\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 26.334053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.025188 -> initscore=-3.655875\n",
      "[LightGBM] [Info] Start training from score -3.655875\n",
      "[LightGBM] [Info] Number of positive: 4513, number of negative: 125906\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 26.138788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.034604 -> initscore=-3.328573\n",
      "[LightGBM] [Info] Start training from score -3.328573\n",
      "[LightGBM] [Info] Number of positive: 308, number of negative: 130111\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 24.093797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002362 -> initscore=-6.046043\n",
      "[LightGBM] [Info] Start training from score -6.046043\n",
      "[LightGBM] [Info] Number of positive: 8515, number of negative: 121904\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 26.963924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065290 -> initscore=-2.661405\n",
      "[LightGBM] [Info] Start training from score -2.661405\n",
      "[LightGBM] [Info] Number of positive: 8512, number of negative: 121907\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 22.084312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065267 -> initscore=-2.661782\n",
      "[LightGBM] [Info] Start training from score -2.661782\n",
      "[LightGBM] [Info] Number of positive: 3581, number of negative: 126838\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 24.316894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.027458 -> initscore=-3.567269\n",
      "[LightGBM] [Info] Start training from score -3.567269\n",
      "[LightGBM] [Info] Number of positive: 781, number of negative: 129638\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 26.209518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.005988 -> initscore=-5.111926\n",
      "[LightGBM] [Info] Start training from score -5.111926\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Number of positive: 8501, number of negative: 121918\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 16.076296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065182 -> initscore=-2.663165\n",
      "[LightGBM] [Info] Start training from score -2.663165\n",
      "[LightGBM] [Info] Number of positive: 3955, number of negative: 126464\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 26.489698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030325 -> initscore=-3.464977\n",
      "[LightGBM] [Info] Start training from score -3.464977\n",
      "[LightGBM] [Info] Number of positive: 329, number of negative: 130090\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 25.358823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002523 -> initscore=-5.979924\n",
      "[LightGBM] [Info] Start training from score -5.979924\n",
      "[LightGBM] [Info] Number of positive: 7938, number of negative: 122481\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 26.195976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.060865 -> initscore=-2.736295\n",
      "[LightGBM] [Info] Start training from score -2.736295\n",
      "[LightGBM] [Info] Number of positive: 388, number of negative: 130031\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 25.061014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002975 -> initscore=-5.814523\n",
      "[LightGBM] [Info] Start training from score -5.814523\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 8504, number of negative: 121915\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 25.233412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065205 -> initscore=-2.662787\n",
      "[LightGBM] [Info] Start training from score -2.662787\n",
      "[LightGBM] [Info] Number of positive: 8512, number of negative: 121907\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 25.640449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065267 -> initscore=-2.661782\n",
      "[LightGBM] [Info] Start training from score -2.661782\n",
      "[LightGBM] [Info] Number of positive: 139, number of negative: 130280\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 27.175092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001066 -> initscore=-6.842967\n",
      "[LightGBM] [Info] Start training from score -6.842967\n",
      "[LightGBM] [Info] Number of positive: 8501, number of negative: 121918\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 17.098822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065182 -> initscore=-2.663165\n",
      "[LightGBM] [Info] Start training from score -2.663165\n",
      "[LightGBM] [Info] Number of positive: 3955, number of negative: 126464\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 25.953094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030325 -> initscore=-3.464977\n",
      "[LightGBM] [Info] Start training from score -3.464977\n",
      "[LightGBM] [Info] Number of positive: 4072, number of negative: 126347\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 26.032602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031222 -> initscore=-3.434898\n",
      "[LightGBM] [Info] Start training from score -3.434898\n",
      "[LightGBM] [Info] Number of positive: 8507, number of negative: 121912\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 22.962677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065228 -> initscore=-2.662410\n",
      "[LightGBM] [Info] Start training from score -2.662410\n",
      "[LightGBM] [Info] Number of positive: 669, number of negative: 129750\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 21.950065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.005130 -> initscore=-5.267581\n",
      "[LightGBM] [Info] Start training from score -5.267581\n",
      "[LightGBM] [Info] Number of positive: 904, number of negative: 129515\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 22.672732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.006932 -> initscore=-4.964723\n",
      "[LightGBM] [Info] Start training from score -4.964723\n",
      "[LightGBM] [Info] Number of positive: 4106, number of negative: 126313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 20.058271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031483 -> initscore=-3.426314\n",
      "[LightGBM] [Info] Start training from score -3.426314\n",
      "[LightGBM] [Info] Number of positive: 5472, number of negative: 124947\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 21.059685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.041957 -> initscore=-3.128245\n",
      "[LightGBM] [Info] Start training from score -3.128245\n",
      "[LightGBM] [Info] Number of positive: 7838, number of negative: 122581\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 25.846634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.060099 -> initscore=-2.749788\n",
      "[LightGBM] [Info] Start training from score -2.749788\n",
      "[LightGBM] [Info] Number of positive: 4072, number of negative: 126347\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 25.059166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031222 -> initscore=-3.434898\n",
      "[LightGBM] [Info] Start training from score -3.434898\n",
      "[LightGBM] [Info] Number of positive: 8507, number of negative: 121912\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 24.195666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065228 -> initscore=-2.662410\n",
      "[LightGBM] [Info] Start training from score -2.662410\n",
      "[LightGBM] [Info] Number of positive: 669, number of negative: 129750\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 25.889958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.005130 -> initscore=-5.267581\n",
      "[LightGBM] [Info] Start training from score -5.267581\n",
      "[LightGBM] [Info] Number of positive: 904, number of negative: 129515\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 20.098413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.006932 -> initscore=-4.964723\n",
      "[LightGBM] [Info] Start training from score -4.964723\n",
      "[LightGBM] [Info] Number of positive: 4106, number of negative: 126313\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 21.024177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031483 -> initscore=-3.426314\n",
      "[LightGBM] [Info] Start training from score -3.426314\n",
      "[LightGBM] [Info] Number of positive: 2387, number of negative: 128032\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 25.045174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018303 -> initscore=-3.982243\n",
      "[LightGBM] [Info] Start training from score -3.982243\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.065198 -> initscore=-2.662913\n",
      "[LightGBM] [Info] Start training from score -2.662913\n",
      "[LightGBM] [Info] Number of positive: 1170, number of negative: 129249\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 21.897958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.008971 -> initscore=-4.704737\n",
      "[LightGBM] [Info] Start training from score -4.704737\n",
      "[LightGBM] [Info] Number of positive: 5866, number of negative: 124553\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 23.584803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.044978 -> initscore=-3.055558\n",
      "[LightGBM] [Info] Start training from score -3.055558\n",
      "[LightGBM] [Info] Number of positive: 4783, number of negative: 125636\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 19.279330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036674 -> initscore=-3.268321\n",
      "[LightGBM] [Info] Start training from score -3.268321\n",
      "[LightGBM] [Info] Number of positive: 354, number of negative: 130065\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 24.199850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002714 -> initscore=-5.906493\n",
      "[LightGBM] [Info] Start training from score -5.906493\n",
      "[LightGBM] [Info] Number of positive: 5472, number of negative: 124947\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 21.681371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255715\n",
      "[LightGBM] [Info] Number of data points in the train set: 130419, number of used features: 5959\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.041957 -> initscore=-3.128245\n",
      "[LightGBM] [Info] Start training from score -3.128245\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=list(y_test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ac85b-1d58-4b7a-b0f2-4599d2314d76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b0cf01926fdba77768c887237a45b31f500b4a49d2ce7769aa1db38997fd2e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
